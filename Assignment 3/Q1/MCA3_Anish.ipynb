{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MCA3_Anish",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc8kbJTh9P2_",
        "colab_type": "code",
        "outputId": "f39d5aa3-13c1-4fe9-dc21-30e69dda0566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('abc')\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import collections\n",
        "import keras\n",
        "from keras import*"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]   Package abc is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gQEwiDmwk9b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e85ad8dc-2d0a-42b8-d932-c657e2acd6a1"
      },
      "source": [
        "#Checking Dataset\n",
        "words = nltk.corpus.abc.words()\n",
        "count = words.count(\"of\")\n",
        "count"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19275"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSpeaYP9QYH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting up dataset with common words\n",
        "topselected = count\n",
        "count = [['UNK', -1]]\n",
        "count.extend(collections.Counter(words).most_common(topselected))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klaQmo2YSlgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = dict()\n",
        "#Creating vector values for the words\n",
        "for word, temp in count:\n",
        "  d[word] = len(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJOz9MdnSnts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Indexing all the dictonary values\n",
        "data = list()\n",
        "null_count = 0\n",
        "\n",
        "for word in words:\n",
        "  if word in d:\n",
        "    data.append(d[word])\n",
        "  else:\n",
        "    data.append(0)\n",
        "    null_count += 1\n",
        "count[0][1] = null_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e68U33wbTjHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Constants\n",
        "wind = 4\n",
        "dim = 700\n",
        "lendata = len(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pHLS0O0VWC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Ensure even distribution of data\n",
        "distribution = keras.preprocessing.sequence.make_sampling_table(lendata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdO5_of22qXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the skipgrams\n",
        "tuples, labels = keras.preprocessing.sequence.skipgrams(data, lendata, window_size=wind, sampling_table=distribution)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1knkfro28eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Random splitting into target and context\n",
        "wt1, wc1 = zip(*tuples)\n",
        "wt = np.array(wt1, dtype=\"int32\")\n",
        "wc = np.array(wc1, dtype=\"int32\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3o1yN324RdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting input variable sizes\n",
        "it = Input((1,))\n",
        "ic = Input((1,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QGNODPR4ZEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating Embedding Layer\n",
        "embedding = keras.layers.Embedding(lendata, dim, input_length=1, name='embedding')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABgL_Cm6bCcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finding embedding vector of target and context\n",
        "target = keras.layers.Reshape((dim, 1))(embedding(it))\n",
        "context = keras.layers.Reshape((dim, 1))(embedding(ic))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsxhoqH_6ZMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Biblio\n",
        "# https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf\n",
        "#python keras documentation\n",
        "#https://adventuresinmachinelearning.com/word2vec-keras-tutorial/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLTgEIAbs5J4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}